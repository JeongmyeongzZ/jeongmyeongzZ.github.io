---
layout: post
title:  "MSA 환경에서 Kafka 사용에 대한 고찰"
date:   2023-12-19 00:40:12
---

## Kafka 를 사용해보자

대부분의 서비스 구조가 API 를 통한 Ack 전달, 또는 사용처에서의 Api 기반 polling 방식이었다.

MSA 환경에서 여러 관심사 별로 마이크로 서비스들이 생기고, 서비스들이 많아질 수록 해당 서비스들에 대한 강한 의존성이 생기기 마련이다.

데이터를 매번 각 서비스에게 전달해줘야했고, 이 분산 서비스 구조 사이의 데이터 전달 과정에서의 트랜잭션 핸들링마저 핸들링 되기 시작한다.

동기 방식이 꼭 필요한 상황에선 Saga pattern, 2PC 과 같은 형태를 구성해야겠지만 일반 커머스 플랫폼에선 이런 강한 트랜잭션이 필요한 행위는 많이 없는 것 같다. 

<br>

이런 문제점들을 해결하기 위해 대규모 서비스를 개편하면서 카프카를 통한 이벤트 발행 방식을 활발하게 사용해보기로 했다.

---

## 겪었던 문제들

직접적으로 "Kafka를 사용해서" 라고 보기는 어렵지만, MSA 환경에선 관심사에 대한 컨텍스트를 나누기가 정말 어렵다.

각 서비스에서 필요한 데이터를 스스로 구축해야하며, 각 서비스에서 정책을 유연하게 주무르려면 발행되는 데이터에 대해 정확한 이해가 필요하다.

"주문"은 특히 커머스에서 많은 서비스들을 통합해 만들어낸 데이터이므로 upstream service 에선 이 데이터가 어떤 데이터인지를 알기 어렵다.

주문 데이터로는 후기도 작성할 수 있으며, 클레임 문의도 작성할 수 있고, 매출, 회계, 정산등에 대한 집계도 이루어질 수 있으며 회원의 혜택이 변경되기도 한다.

<br>

### Payload

*첫 도입시에 발목을 잡은 게 우선 발행되는 메시지 구조였다.*

각 도메인에서 원하는 주문 데이터를 원하는 구조에 맞게 payload 를 설계하기가 정말 어렵다.

주문서에서 상품을 결제하는 단순한 행위처럼 보이지만 내부적으론 배송을 어떻게 해야할지, 각 셀러들의 상품에 할인 금액은 어떻게 분배 되는지 등 엄청나게 많은 일들이 일어나게 되는데, 이게 메시지를 소비(consume) 하는 구독자(subscriber) 들에겐 너무 과한 메시지일 수 있다.

또 반대로 메시지를 너무 빈약하게 설계한다면 회계/정산 처리는 이런 자세한 금액정보나 배송정보들이 부족하다고 느낄 수 있다.

zero payload 와 같은 방식으로 설계 후 각 서비스에 알맞은 api 를 제공해주는 방법도 생각 해볼 수 있지만, 또 주문 데이터는 그 행위가 일어난 시점의 데이터가(snapshot) 중요할 수 있다.

또, 서비스는 항상 확장된다.

처음 설계했던 데이터 구조가 크게 변경되어 기존 payload 로는 의도한 모든 데이터를 담아내기 어려울 수도 있다.

...


